{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn3JKEXckdkL+3zH5+wptm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil2374/Big-Data/blob/main/exp_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zn5Bfu6phiS",
        "outputId": "89707a79-4924-4d7f-d895-5271bc9b92f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Volume (Rows, Columns): (7, 4)\n",
            "\n",
            "Variety (Data Types):\n",
            " CustomerID      int64\n",
            "Date           object\n",
            "Amount        float64\n",
            "Quantity        int64\n",
            "dtype: object\n",
            "\n",
            "Unique Values:\n",
            " CustomerID    6\n",
            "Date          6\n",
            "Amount        5\n",
            "Quantity      5\n",
            "dtype: int64\n",
            "\n",
            "Velocity (Average Time Difference): Not Applicable\n",
            "\n",
            "Missing Data (Per Column):\n",
            " CustomerID    0\n",
            "Date          0\n",
            "Amount        1\n",
            "Quantity      0\n",
            "dtype: int64\n",
            "\n",
            "Value Analysis (Summary Statistics):\n",
            "        CustomerID      Amount  Quantity\n",
            "count    7.000000    6.000000  7.000000\n",
            "mean   103.142857  333.500000  2.714286\n",
            "std      1.951800  193.890175  1.380131\n",
            "min    101.000000  150.500000  1.000000\n",
            "25%    101.500000  162.875000  2.000000\n",
            "50%    103.000000  300.000000  2.000000\n",
            "75%    104.500000  475.000000  3.500000\n",
            "max    106.000000  600.000000  5.000000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_big_data(dataset_path):\n",
        "\n",
        "    try:\n",
        "        # Step 1: Load the dataset\n",
        "        data = pd.read_csv(dataset_path)\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: File not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "    # Step 2: Volume - Count number of rows and columns\n",
        "    volume = data.shape  # (rows, columns)\n",
        "\n",
        "    # Step 3: Variety - Check data types and unique values\n",
        "    variety = data.dtypes\n",
        "    unique_values = data.nunique()\n",
        "\n",
        "    # Step 4: Velocity - Estimate update frequency (if time-based data available)\n",
        "    if 'timestamp' in data.columns:\n",
        "        try:\n",
        "            data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce')\n",
        "            if data['timestamp'].isna().all():\n",
        "                velocity = \"Timestamp column has invalid data.\"\n",
        "            else:\n",
        "                velocity = data['timestamp'].diff().mean()  # Average time between entries\n",
        "        except Exception as e:\n",
        "            velocity = f\"Error processing timestamp: {e}\"\n",
        "    else:\n",
        "        velocity = \"Not Applicable\"\n",
        "\n",
        "    # Step 5: Veracity - Check for missing values or inconsistencies\n",
        "    missing_data = data.isnull().sum()\n",
        "\n",
        "    # Step 6: Value - Perform basic analysis (e.g., mean, median) for numeric data\n",
        "    numeric_data = data.select_dtypes(include=np.number)\n",
        "    value = numeric_data.describe()  # Summary statistics for numeric columns\n",
        "\n",
        "    # Step 7: Return all 5 V's results\n",
        "    return volume, variety, unique_values, velocity, missing_data, value\n",
        "\n",
        "# Example usage\n",
        "dataset_path = '/content/GP.csv'  # Replace with the actual path to your dataset\n",
        "result = analyze_big_data(dataset_path)\n",
        "\n",
        "# Output results\n",
        "if isinstance(result, str):  # Error message\n",
        "    print(result)\n",
        "else:\n",
        "    volume, variety, unique_values, velocity, missing_data, value = result\n",
        "    print(\"\\nVolume (Rows, Columns):\", volume)\n",
        "    print(\"\\nVariety (Data Types):\\n\", variety)\n",
        "    print(\"\\nUnique Values:\\n\", unique_values)\n",
        "    print(\"\\nVelocity (Average Time Difference):\", velocity)\n",
        "    print(\"\\nMissing Data (Per Column):\\n\", missing_data)\n",
        "    print(\"\\nValue Analysis (Summary Statistics):\\n\", value)\n"
      ]
    }
  ]
}